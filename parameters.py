import os

# define transBG-specific parameters
params = {
    #Training and validation set for energy-based learning
    "energy_train_indices" : [1, 2, 4, 5, 6, 7, 11, 13],
    "energy_val_indices" : [0, 9, 10],
    "max_energies" : [10000., 10000., 10000., 10000., 10000., 10000., 10000., 10000.], # Old: [150., 100., 200., 200., 500., 200., 400., 400.]
    "hist_evo" : False,
    "hist_conf" : 1000,
    "finetune_l" : False, # If True, before e-bl is performed, the model trains only using lb-l on energy_train_indices.

    "model_name" : "test",
    "device" : "cuda:0",

    "random_seed" : 0,

    # Dataset parameters
    "max_nodes" : 29,
    "atom_types" : [ [1], [6], [7], [8], [9] ],
    "bond_types" : [ [1], [2], [3], [1.5] ],
    "dataset_size" :  131081, #133885 before cleaning 131081 after. 8192 for hpo.

    # Training parameters
    "batch_size" : 128, # molecules #64 256 tried, 128 for hps
    "e_batch_size" : 2, # molecules 4 8
    "val_set_size" : 0.2,
    "test_set_size" : 0.,
    "l_epochs" : 50, # Number of epochs to train on likelihood
    "ft_epochs" : 20, # Number of epochs to fine-tune on likelihood on the energy based training set. Check with validation loss: Compromise speed of training with overfitting.
    "e_epochs" : 50, # Number of epochs to train on energy
    "l_learning_rate" : 5e-4, # If scheduler is used, this is the initial lr. 1e-4 standard. (Greater than 1e-3 creates incosistent response for cpu and gpu -> overflow.)
    "l_max_rel_lr" : 1.,
    "l_min_rel_lr" : 1./20, # 1./50 standard
    "ft_learning_rate" : 1e-5,
    "ft_max_rel_lr" : 1.,
    "ft_min_rel_lr" : 1./10,
    "e_learning_rate" : 5e-5, # 1e-4 # >= 5e-4 returns nans
    "e_max_rel_lr" : 1.,
    "e_min_rel_lr" : 1./20, # 1./20
    "weight_decay" : 1e-5, # 1e-5

    "train_GNN_ebl" : True,
    "train_schnet_ebl" : True,

    "l_weight" : .01, #Weight of likelihood loss when training on energy. between 0 and 1. Energy loss is 1-l_weight
    "n_conformations" : 1024, #Number of conformations generated by the model for each molecule in every energy based learning step 1024 

     "cartesian" : False,# If true cartesian coordinates are used to generate the conformations, if not, internal coordinates are used.

    # NVP parameters
    "num_coupling_layers" : 12, # Number of times each coordinate is transformed, not number of NVP blocks (number of dimensions * num_coupling_layers) #12
    "intermediate_rep_size" :  256, #256

    # Representations parameters
    "mol_rep_size" : 64, #128
    "atom_rep_size" : 64, #128  (At least the number of atom features)
    "schnet_rep_size" : 64, #64
    "ref_frame_rep_size" : 12,
    "add_symmerty_token" : True,

    # GGNN specific parameters
    "enn_depth" : 2,
    "enn_dropout_p" : 0,
    "enn_hidden_dim" : 128, #256
    "gather_att_depth" : 2,
    "gather_att_dropout_p" : 0,
    "gather_att_hidden_dim" : 64, #128
    "gather_emb_depth" : 2,
    "gather_emb_dropout_p" : 0,
    "gather_emb_hidden_dim" : 128, #256
    "weights_initialization" : "uniform", # or "normal"
    "message_passes" : 3,
    "message_size" : 64, #128
    "model" : "GGNN",

    # SchNet parameters
    "n_interactions" : 3, # 3
    "cutoff" : 5.0,    # 5.0
    "n_gaussians" : 25, # 25
    "normalize_filter" : False, #False
    "coupled_interactions"  :False, #False
    "trainable_gaussians" : False, #False
}

#add relative parameters
params["node_features"] = len(params["atom_types"])# Assume we only include info about the atom type in the node features.,
params["edge_features"] = len(params["bond_types"])
params["e_weight"] = 1. - params["l_weight"] #Weight of energy loss when training on energy, the sum of both weights must be 1 (convex sum)

if params["add_symmerty_token"]:
    params["symmetry_token_size"] = 3
else:
    params["symmetry_token_size"] = 0

if params["cartesian"]:
    ref_frame_rep_size : 0

params["gather_width"] = params["mol_rep_size"]
params["hidden_node_features"] = params["atom_rep_size"]

params["max_n_nodes"] = params["max_nodes"]
params["dim_edges"] = [ params["max_nodes"], params["max_nodes"], params["edge_features"] ]
params["dim_nodes"] = [ params["max_nodes"], params["node_features"] ]

params["max_z"] = max([ item for sublist in params["atom_types"] for item in sublist ])

cwd = os.getcwd()
#Paths to the sdf and xyz files (we need the xyz to read the partial charges)
params["sdf_path"] = "./datasets/QM9/qm9/clean_gdb9.sdf"  # datasets/QM9/small_dataset_sdf
params["xyz_path"] = "./datasets/QM9/dsgdb9nsd_xyz" # both dataset folders are comunicated through the labels of the molecules
params["pdb_path"] = "./datasets/QM9/qm9_conformations" # data from md simulations

#Fine-tuned model to load for e-bl
params["pre_trained_model"] = './models/nl_12l_lr5e-4'